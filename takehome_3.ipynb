{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3ec6451c-dcb5-4559-ad14-2e0e08166351",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pip install mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "46d63ee8-7bce-4cd2-924e-006979b7d066",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# import relevant functions\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import boto3\n",
    "import mlflow.sklearn\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7f58cee9-1547-400d-8079-550f2e592383",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "s3 = boto3.client('s3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5646d330-0808-4189-b301-16d1a21c81af",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# import data\n",
    "bucket = \"columbia-gr5069-main\"\n",
    "drivers_data = \"raw/drivers.csv\"\n",
    "races_data = \"raw/races.csv\"\n",
    "results_data = \"raw/results.csv\"\n",
    "\n",
    "drivers = s3.get_object(Bucket= bucket, Key= drivers_data) \n",
    "races = s3.get_object(Bucket= bucket, Key= races_data) \n",
    "results = s3.get_object(Bucket= bucket, Key= results_data) \n",
    "\n",
    "df_drivers = pd.read_csv(drivers[\"Body\"])\n",
    "df_races = pd.read_csv(races[\"Body\"])\n",
    "df_results = pd.read_csv(results[\"Body\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "adec2916-54c8-47f4-a758-8a1e0243e3f9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(df_drivers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "858826a5-ba8b-46b3-addc-92d60f2199ea",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(df_races)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e909b18c-ccbc-4f92-b4ed-3feb11829988",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(df_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c1b9ee64-315e-4e6d-a705-4bee55640949",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# merge dataframes \n",
    "drivers_results = pd.merge(df_results, df_drivers, on=\"driverId\", how=\"left\")\n",
    "drivers_results = pd.merge(drivers_results, df_races, on=\"raceId\", how=\"left\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1d290cd7-1b5f-41c5-9508-6acb1877540d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# calculate age of drivers at time of race\n",
    "drivers_results['dob'] = pd.to_datetime(drivers_results['dob'])\n",
    "drivers_results['date'] = pd.to_datetime(drivers_results['date'])\n",
    "drivers_results['age'] = (drivers_results['date'].dt.year - drivers_results['dob'].dt.year) - ((\n",
    "    drivers_results['date'].dt.year - drivers_results['dob'].dt.month) < 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e1310ec3-ebdf-433c-a97b-ef5825253ead",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# one-hot encode nationality\n",
    "drivers_results = pd.get_dummies(drivers_results, columns=[\"nationality\"])\n",
    "display(drivers_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fd91f0c7-526f-4c00-bf93-27a8933732bf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# display final dataframe\n",
    "df = drivers_results[[\"raceId\", \"driverId\", \"positionOrder\", \"age\", \n",
    "                         \"nationality_American\", \n",
    "                         \"nationality_American-Italian\", \n",
    "                         \"nationality_Argentine\", \n",
    "                         \"nationality_Argentine-Italian\", \n",
    "                         \"nationality_Australian\", \n",
    "                         \"nationality_Austrian\", \n",
    "                         \"nationality_Belgian\", \n",
    "                         \"nationality_Brazilian\", \n",
    "                         \"nationality_British\", \n",
    "                         \"nationality_Canadian\", \n",
    "                         \"nationality_Chilean\", \n",
    "                         \"nationality_Chinese\", \n",
    "                         \"nationality_Colombian\", \n",
    "                         \"nationality_Czech\", \n",
    "                         \"nationality_Danish\", \n",
    "                         \"nationality_Dutch\", \n",
    "                         \"nationality_East German\", \n",
    "                         \"nationality_Finnish\", \n",
    "                         \"nationality_French\", \n",
    "                         \"nationality_German\", \n",
    "                         \"nationality_Hungarian\", \n",
    "                         \"nationality_Indian\", \n",
    "                         \"nationality_Indonesian\", \n",
    "                         \"nationality_Irish\", \n",
    "                         \"nationality_Italian\", \n",
    "                         \"nationality_Japanese\", \n",
    "                         \"nationality_Liechtensteiner\", \n",
    "                         \"nationality_Malaysian\", \n",
    "                         \"nationality_Mexican\", \n",
    "                         \"nationality_Monegasque\", \n",
    "                         \"nationality_New Zealander\", \n",
    "                         \"nationality_Polish\", \n",
    "                         \"nationality_Portuguese\", \n",
    "                         \"nationality_Rhodesian\", \n",
    "                         \"nationality_Russian\", \n",
    "                         \"nationality_South African\", \n",
    "                         \"nationality_Spanish\", \n",
    "                         \"nationality_Swedish\", \n",
    "                         \"nationality_Swiss\", \n",
    "                         \"nationality_Thai\", \n",
    "                         \"nationality_Uruguayan\", \n",
    "                         \"nationality_Venezuelan\"]]\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d0bcb466-3249-4612-9259-acb625a62c0e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# split data into training and test subsets\n",
    "y = df[\"positionOrder\"]\n",
    "X = df.loc[:,[\"age\",\n",
    "                \"nationality_American\", \n",
    "                \"nationality_American-Italian\", \n",
    "                \"nationality_Argentine\", \n",
    "                \"nationality_Argentine-Italian\", \n",
    "                \"nationality_Australian\", \n",
    "                \"nationality_Austrian\", \n",
    "                \"nationality_Belgian\", \n",
    "                \"nationality_Brazilian\", \n",
    "                \"nationality_British\", \n",
    "                \"nationality_Canadian\", \n",
    "                \"nationality_Chilean\", \n",
    "                \"nationality_Chinese\", \n",
    "                \"nationality_Colombian\", \n",
    "                \"nationality_Czech\", \n",
    "                \"nationality_Danish\", \n",
    "                \"nationality_Dutch\", \n",
    "                \"nationality_East German\", \n",
    "                \"nationality_Finnish\", \n",
    "                \"nationality_French\", \n",
    "                \"nationality_German\", \n",
    "                \"nationality_Hungarian\", \n",
    "                \"nationality_Indian\", \n",
    "                \"nationality_Indonesian\", \n",
    "                \"nationality_Irish\", \n",
    "                \"nationality_Italian\", \n",
    "                \"nationality_Japanese\", \n",
    "                \"nationality_Liechtensteiner\", \n",
    "                \"nationality_Malaysian\", \n",
    "                \"nationality_Mexican\", \n",
    "                \"nationality_Monegasque\", \n",
    "                \"nationality_New Zealander\", \n",
    "                \"nationality_Polish\", \n",
    "                \"nationality_Portuguese\", \n",
    "                \"nationality_Rhodesian\", \n",
    "                \"nationality_Russian\", \n",
    "                \"nationality_South African\", \n",
    "                \"nationality_Spanish\", \n",
    "                \"nationality_Swedish\", \n",
    "                \"nationality_Swiss\", \n",
    "                \"nationality_Thai\", \n",
    "                \"nationality_Uruguayan\", \n",
    "                \"nationality_Venezuelan\"]]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dec43761-5e5f-49f8-b425-8e9cc0b8b8f7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_name=\"Basic RF Experiment\") as run:\n",
    "  # Create model, train it, and create predictions\n",
    "  rf = RandomForestRegressor()\n",
    "  rf.fit(X_train, y_train)\n",
    "  predictions = rf.predict(X_test)\n",
    "  \n",
    "  # Log model\n",
    "  mlflow.sklearn.log_model(rf, \"random-forest-model\")\n",
    "  \n",
    "  # Create metrics\n",
    "  mse = mean_squared_error(y_test, predictions)\n",
    "  print(\"  mse: {}\".format(mse))\n",
    "  \n",
    "  # Log metrics\n",
    "  mlflow.log_metric(\"mse\", mse)\n",
    "  \n",
    "  runID = run.info.run_uuid\n",
    "  experimentID = run.info.experiment_id\n",
    "  \n",
    "  print(\"Inside MLflow Run with run_id {} and experiment_id {}\".format(runID, experimentID))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1b9ec439-f442-4a14-9afc-1225f5b4ade5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def log_rf(experimentID, run_name, params, X_train, X_test, y_train, y_test):\n",
    "  import os\n",
    "  import matplotlib.pyplot as plt\n",
    "  import mlflow.sklearn\n",
    "  import seaborn as sns\n",
    "  from sklearn.ensemble import RandomForestRegressor\n",
    "  from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, explained_variance_score, mean_absolute_percentage_error, mean_squared_log_error\n",
    "  import tempfile\n",
    "\n",
    "  with mlflow.start_run(experiment_id=experimentID, run_name=run_name) as run:\n",
    "    # Create model, train it, and create predictions\n",
    "    rf = RandomForestRegressor(**params)\n",
    "    rf.fit(X_train, y_train)\n",
    "    predictions = rf.predict(X_test)\n",
    "\n",
    "    # Log model\n",
    "    mlflow.sklearn.log_model(rf, \"random-forest-model\")\n",
    "\n",
    "    # Log params\n",
    "    [mlflow.log_param(param, value) for param, value in params.items()]\n",
    "\n",
    "    # Create metrics\n",
    "    mse = mean_squared_error(y_test, predictions)\n",
    "    mae = mean_absolute_error(y_test, predictions)\n",
    "    rmse = mean_squared_error(y_test, predictions, squared=False)\n",
    "    r2 = r2_score(y_test, predictions)\n",
    "    mape = mean_absolute_percentage_error(y_test, predictions)\n",
    "    evs = explained_variance_score(y_test, predictions)\n",
    "    msle = mean_squared_log_error(y_test, predictions)\n",
    "    print(\"  mse: {}\".format(mse))\n",
    "    print(\"  mae: {}\".format(mae))\n",
    "    print(\"  rmse: {}\".format(rmse))\n",
    "    print(\"  R2: {}\".format(r2))\n",
    "    print(\"  mape: {}\".format(mape))\n",
    "    print(\"  evs: {}\".format(evs))\n",
    "    print(\"  msle: {}\".format(msle))\n",
    "\n",
    "    # Log metrics\n",
    "    mlflow.log_metric(\"mse\", mse)\n",
    "    mlflow.log_metric(\"mae\", mae)  \n",
    "    mlflow.log_metric(\"r2\", r2) \n",
    "    mlflow.log_metric(\"rmse\", rmse)\n",
    "    mlflow.log_metric(\"mape\", mape)  \n",
    "    mlflow.log_metric(\"evs\", evs)\n",
    "    mlflow.log_metric(\"msle\", msle)  \n",
    "    \n",
    "    # Create feature importance\n",
    "    importance = pd.DataFrame(list(zip(df.columns, rf.feature_importances_)), \n",
    "                                columns=[\"Feature\", \"Importance\"]\n",
    "                              ).sort_values(\"Importance\", ascending=False)\n",
    "    \n",
    "    # Log importances using a temporary file\n",
    "    temp = tempfile.NamedTemporaryFile(prefix=\"feature-importance-\", suffix=\".csv\")\n",
    "    temp_name = temp.name\n",
    "    try:\n",
    "      importance.to_csv(temp_name, index=False)\n",
    "      mlflow.log_artifact(temp_name, \"feature-importance.csv\")\n",
    "    finally:\n",
    "      temp.close() # Delete the temp file\n",
    "    \n",
    "    # Create plot\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    sns.residplot(x=predictions, y=y_test, lowess=True)\n",
    "    plt.xlabel(\"Predicted values position order\")\n",
    "    plt.ylabel(\"Residual\")\n",
    "    plt.title(\"Residual Plot\")\n",
    "\n",
    "    # Log residuals using a temporary file\n",
    "    temp = tempfile.NamedTemporaryFile(prefix=\"residuals-\", suffix=\".png\")\n",
    "    temp_name = temp.name\n",
    "    try:\n",
    "      fig.savefig(temp_name)\n",
    "      mlflow.log_artifact(temp_name, \"residuals.png\")\n",
    "    finally:\n",
    "      temp.close() # Delete the temp file\n",
    "\n",
    "    # Log predictions  \n",
    "    pred = pd.DataFrame({\"Predictions\": predictions, \"Actual\": y_test})\n",
    "    pred_path = \"predictions.csv\"\n",
    "    pred.to_csv(pred_path, index=False)\n",
    "    mlflow.log_artifact(pred_path)\n",
    "    \n",
    "    return run.info.run_uuid"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "takehome_3",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
